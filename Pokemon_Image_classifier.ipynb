{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1tSMbzSOCQZQXT8oOPy6zn6iG8zSuODFL",
      "authorship_tag": "ABX9TyNtWlPOac8wvYk32FP5q1ED",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nawazwariya182/Nawazwariya182/blob/main/Pokemon_Image_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wfwTqgrr0xMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import zipfile\n",
        "# import os\n",
        "\n",
        "# zip_path = '/content/drive/MyDrive/ds.zip'  # update this\n",
        "# extract_to = '/content'\n",
        "\n",
        "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(extract_to)\n",
        "\n",
        "# print(\"✅ ZIP extracted to /content\")\n"
      ],
      "metadata": {
        "id": "vUsGC4gI0zvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pyright: reportMissingImports=false\n",
        "!pip install gradio\n",
        "!pip install tensorflow\n",
        "!pip install pillow\n",
        "import google.colab\n",
        "IN_COLAB = 'google.colab' in str(google.colab.__file__)\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "import time"
      ],
      "metadata": {
        "id": "b66oRy2rmNYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "try:\n",
        "    policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "    tf.keras.mixed_precision.set_global_policy(policy)\n",
        "    print('Mixed precision enabled')\n",
        "except:\n",
        "    print('Mixed precision not enabled')"
      ],
      "metadata": {
        "id": "NWK_0IZZmhYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(num_classes):\n",
        "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "    base_model.trainable = False\n",
        "\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "uQnP0xR1mlB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_dir):\n",
        "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        validation_split=0.2,\n",
        "        subset=\"training\",\n",
        "        seed=123,\n",
        "        image_size=(128, 128),\n",
        "        batch_size=128\n",
        "    )\n",
        "\n",
        "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        validation_split=0.2,\n",
        "        subset=\"validation\",\n",
        "        seed=123,\n",
        "        image_size=(128, 128),\n",
        "        batch_size=128\n",
        "    )\n",
        "\n",
        "    class_names = train_ds.class_names\n",
        "\n",
        "    normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "\n",
        "    train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "    val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "    train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "    val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    return train_ds, val_ds, class_names\n"
      ],
      "metadata": {
        "id": "v42C-5AkmnHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(data_dir, model_save_path='pokemon_model.h5'):\n",
        "    print(f\"Loading data from: {data_dir}\")\n",
        "    train_ds, val_ds, class_names = load_data(data_dir)\n",
        "    num_classes = len(class_names)\n",
        "    print(f\"Training with {num_classes} Pokémon classes\")\n",
        "\n",
        "    model = create_model(num_classes)\n",
        "\n",
        "    # Callbacks configuration\n",
        "    callbacks = [\n",
        "        # Early stopping after no improvement for 10 epochs\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),\n",
        "\n",
        "        # Reduce learning rate when validation loss plateaus\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001),\n",
        "\n",
        "        # Save the best model based on validation accuracy\n",
        "        tf.keras.callbacks.ModelCheckpoint(model_save_path, save_best_only=True, monitor='val_accuracy')\n",
        "    ]\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=50,  # Adjusted epochs to 100\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"Training completed in {training_time/60:.2f} minutes\")\n",
        "\n",
        "    model.save(model_save_path)\n",
        "\n",
        "    return model, class_names\n"
      ],
      "metadata": {
        "id": "npz6YZEHmpSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_pokemon(img, model_path='pokemon_model.h5', class_names=None):\n",
        "    if isinstance(img, np.ndarray):\n",
        "        img_pil = Image.fromarray(img.astype('uint8'))\n",
        "    else:\n",
        "        img_pil = Image.open(img).convert('RGB')\n",
        "\n",
        "    img_pil = img_pil.resize((128, 128))\n",
        "    img_array = np.array(img_pil) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    model = load_model(model_path)\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class_idx = np.argmax(prediction[0])\n",
        "\n",
        "    if class_names:\n",
        "        return class_names[predicted_class_idx]\n",
        "    else:\n",
        "        return f\"Class index: {predicted_class_idx}\""
      ],
      "metadata": {
        "id": "aIb-TFQEmsh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_gradio_interface(model_path='pokemon_model.h5', class_names=None):\n",
        "    def predict_image(image):\n",
        "        return predict_pokemon(image, model_path, class_names)\n",
        "\n",
        "    interface = gr.Interface(\n",
        "        fn=predict_image,\n",
        "        inputs=gr.Image(),\n",
        "        outputs=gr.Textbox(label=\"Predicted Pokémon\"),\n",
        "        title=\"Pokémon Classifier\",\n",
        "        description=\"Upload an image of a Pokémon and get a prediction\"\n",
        "    )\n",
        "\n",
        "    return interface"
      ],
      "metadata": {
        "id": "BOIOX8QYmt_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0c9dV7Llzqv"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    data_dir = \"/content/ds/pokemon-dataset-1000/dataset/\"\n",
        "    model_path = \"pokemon_model.h5\"\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        try:\n",
        "            folders = os.listdir(data_dir)\n",
        "            print(f\"Found {len(folders)} Pokémon classes in the dataset\")\n",
        "            if len(folders) > 0:\n",
        "                print(f\"Sample classes: {folders[:5]}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error accessing dataset: {e}\")\n",
        "\n",
        "        model, class_names = train_model(data_dir, model_path)\n",
        "    else:\n",
        "        _, _, class_names = load_data(data_dir)\n",
        "\n",
        "    interface = setup_gradio_interface(model_path, class_names)\n",
        "    interface.launch(share=True if IN_COLAB else False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "\n",
        "def load_data1(data_dir):\n",
        "    # Load training and validation datasets\n",
        "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        validation_split=0.2,\n",
        "        subset=\"training\",\n",
        "        seed=123,\n",
        "        image_size=(128, 128),\n",
        "        batch_size=128\n",
        "    )\n",
        "\n",
        "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        validation_split=0.2,\n",
        "        subset=\"validation\",\n",
        "        seed=123,\n",
        "        image_size=(128, 128),\n",
        "        batch_size=128\n",
        "    )\n",
        "\n",
        "    # Get the class names\n",
        "    class_names = train_ds.class_names\n",
        "\n",
        "    # Save the class names to a JSON file\n",
        "    with open('class_names.json', 'w') as f:\n",
        "        json.dump(class_names, f)\n",
        "\n",
        "    # Normalize the images\n",
        "    normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "\n",
        "    # Apply the normalization to the datasets\n",
        "    train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "    val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "    # Cache and prefetch for better performance\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "    train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "    val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    return train_ds, val_ds, class_names\n"
      ],
      "metadata": {
        "id": "CBTKKAlR8wjS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}